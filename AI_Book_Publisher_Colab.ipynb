{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulraimau/ai-book-publisher/blob/main/AI_Book_Publisher_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e777295",
      "metadata": {
        "id": "3e777295"
      },
      "source": [
        "# ğŸ“š AI Book Publisher - Google Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14068536",
      "metadata": {
        "id": "14068536"
      },
      "source": [
        "You're now ready to run `pipeline.py`, `app.py`, or individual components!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai sentence-transformers beautifulsoup4 nltk"
      ],
      "metadata": {
        "id": "q60_Vdvo8QKU"
      },
      "id": "q60_Vdvo8QKU",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkjD8_1l8wD8",
        "outputId": "097999d5-ae0a-43e2-c1d8-bb0406721073"
      },
      "id": "nkjD8_1l8wD8",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GEMINI_API_KEY'] = \"AIzaSyAjuRwW8XKIGV8u2xmeQ7lPcABRuHlSSYE\""
      ],
      "metadata": {
        "id": "Waogsfzh2xS9"
      },
      "id": "Waogsfzh2xS9",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, requests, nltk, uuid\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import google.generativeai as genai\n",
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
        "from gtts import gTTS\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Gemini API setup\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "reward_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# ChromaDB setup\n",
        "chroma_client = chromadb.Client()\n",
        "embedding_fn = SentenceTransformerEmbeddingFunction(\"all-MiniLM-L6-v2\")\n",
        "collection = chroma_client.create_collection(\"chapters\", embedding_function=embedding_fn)\n",
        "\n",
        "# Step 1: Scrape chapter\n",
        "def fetch_chapter(url):\n",
        "    res = requests.get(url)\n",
        "    soup = BeautifulSoup(res.text, 'html.parser')\n",
        "    paragraphs = soup.select(\"div#mw-content-text p\")\n",
        "    return \"\\n\\n\".join([p.get_text() for p in paragraphs if len(p.get_text()) > 50])\n",
        "\n",
        "# Step 2: Use Gemini to rewrite chapter\n",
        "def ai_writer(text):\n",
        "    model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
        "    prompt = f\"Paraphrase and creatively rewrite the following chapter text:\\n\\n{text[:2000]}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# Step 3: RL-style reviewer\n",
        "def ai_reviewer(original, spun):\n",
        "    orig_tokens = set(nltk.word_tokenize(original.lower()))\n",
        "    spun_tokens = set(nltk.word_tokenize(spun.lower()))\n",
        "    jaccard_sim = len(orig_tokens & spun_tokens) / len(orig_tokens | spun_tokens)\n",
        "    orig_emb = reward_model.encode(original, convert_to_tensor=True)\n",
        "    spun_emb = reward_model.encode(spun, convert_to_tensor=True)\n",
        "    sim = util.pytorch_cos_sim(orig_emb, spun_emb).item()\n",
        "    novelty = 1 - sim\n",
        "    reward = 0.4 * sim + 0.4 * novelty + 0.2 * (1 - jaccard_sim)\n",
        "    return {\n",
        "        \"semantic_similarity\": round(sim, 3),\n",
        "        \"novelty\": round(novelty, 3),\n",
        "        \"jaccard_diversity\": round(1 - jaccard_sim, 3),\n",
        "        \"final_reward_score\": round(reward, 3)\n",
        "    }\n",
        "\n",
        "# Step 4: TTS feedback\n",
        "def speak(text, filename=\"tts_output.mp3\"):\n",
        "    tts = gTTS(text)\n",
        "    tts.save(filename)\n",
        "    return filename\n",
        "\n",
        "# Step 5: Save version to ChromaDB\n",
        "def save_version(text, meta):\n",
        "    version_id = str(uuid.uuid4())\n",
        "    collection.add(documents=[text], metadatas=[meta], ids=[version_id])\n",
        "    return version_id\n",
        "\n",
        "# Step 6: Semantic search among versions\n",
        "def semantic_search(query_text):\n",
        "    result = collection.query(query_texts=[query_text], n_results=1)\n",
        "    return result['documents'][0] if result['documents'] else \"No match found.\"\n",
        "\n",
        "# Full human-in-the-loop workflow\n",
        "def run_interactive_pipeline(url):\n",
        "    original = fetch_chapter(url)\n",
        "    current = ai_writer(original)\n",
        "    print(\"\\nğŸŒ€ AI-Spun Version (excerpt):\\n\", current[:400])\n",
        "\n",
        "    for i in range(3):\n",
        "        print(f\"\\nâœï¸ Iteration {i+1}: You may refine the text manually below\")\n",
        "        current = input(\"\\nYour rewrite (or press Enter to keep AI version):\\n\") or current\n",
        "        reward = ai_reviewer(original[:512], current)\n",
        "        version_id = save_version(current, {\"iteration\": i + 1, \"reward\": reward})\n",
        "        print(\"âœ… Reward:\", reward)\n",
        "        print(\"ğŸ’¾ Saved as version:\", version_id)\n",
        "        speak(current[:300], f\"readout_{i+1}.mp3\")\n",
        "\n",
        "    return current, reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU65FWMX8XGk",
        "outputId": "8ccc13ca-7fe1-403a-8621-c73258fc23dd"
      },
      "id": "wU65FWMX8XGk",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chapter_url = \"https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1\"\n",
        "\n",
        "original, spun, reward = run_pipeline(chapter_url)\n",
        "\n",
        "print(\"ğŸ“˜ Original (excerpt):\\n\", original[:400], \"\\n\")\n",
        "print(\"ğŸŒ€ Spun Version (excerpt):\\n\", spun[:400], \"\\n\")\n",
        "print(\"ğŸ† RL Reward Metrics:\\n\", reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "cuTROYsH8c3b",
        "outputId": "563a659d-595c-4cf9-b245-a22d2f2a90ec"
      },
      "id": "cuTROYsH8c3b",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“˜ Original (excerpt):\n",
            " DICK standing on a ledge of coral cast his eyes to the South.\n",
            "\n",
            "\n",
            "Behind him the breakers of the outer sea thundered and the spindrift scattered on the wind; before him stretched an ocean calm as a lake, infinite, blue, and flown about by the fishing gullsâ€”the lagoon of Karolin.\n",
            "\n",
            "\n",
            "Clipped by its forty-mile ring of coral this great pond was a sea in itself, a sea of storm in heavy winds, a lake of az \n",
            "\n",
            "ğŸŒ€ Spun Version (excerpt):\n",
            " High on a coral shelf, Dick surveyed his kingdom.  The furious ocean roared behind him, a stark contrast to the placid, sapphire lagoon of Karolin stretching before â€“ a forty-mile ring of coral cradling a sea that shifted between tempest and tranquility.  It was *his* sea now, claimed just yesterday.\n",
            "\n",
            "Below, the vibrant tapestry of Karolin's life unfolded in the sun-drenched sand: women mending ne \n",
            "\n",
            "ğŸ† RL Reward Metrics:\n",
            " {'semantic_similarity': 0.493, 'novelty': 0.507, 'jaccard_diversity': 0.87, 'final_reward_score': 0.574}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6be83fe",
        "outputId": "e451e9b1-1de6-468e-d44c-71fe7faadcf7"
      },
      "source": [
        "!pip install -q gtts"
      ],
      "id": "f6be83fe",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}